{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S89AJpQYG3du"
   },
   "outputs": [],
   "source": [
    "# 딥러닝 기본 모델 사용할 때 참고해본다.\n",
    "\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bpe2e0QhvLKX"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "SAVED_MODEL_DIR = './saved_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fc96HiziSiOR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\lemon\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d95a4820964d0d8d5798bd748c15bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eec89646b594712bd17c4f35352d53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e153c621744b898c218697c0c222fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling mnist-train.tfrecord...:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling mnist-test.tfrecord...:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\lemon\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "(ds_train_data, ds_val_data), info = tfds.load(\n",
    "    name='mnist',\n",
    "    split=['train', 'test'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "num_classes = info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8N_qOpgSlLG"
   },
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "ds_train = (\n",
    "    ds_train_data\n",
    "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(info.splits['train'].num_examples)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_val = (\n",
    "    ds_val_data\n",
    "    .map(preprocess, AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Lq0YDUYiTMN"
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(28, 28, 1), name='input')\n",
    "\n",
    "x = layers.Conv2D(24, kernel_size=(6, 6), strides=1)(inputs)\n",
    "x = layers.BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "x = layers.Conv2D(48, kernel_size=(5, 5), strides=2)(x)\n",
    "x = layers.BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "x = layers.Conv2D(64, kernel_size=(4, 4), strides=2)(x)\n",
    "x = layers.BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(200)(x)\n",
    "x = layers.BatchNormalization(scale=False, beta_initializer=Constant(0.01))(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "predications = layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predications)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBzYWAEAiwzx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 23, 23, 24)        888       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 23, 23, 24)        72        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 23, 23, 24)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 23, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 10, 48)        144       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          49216     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 64)          192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 200)               600       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 286,970\n",
      "Trainable params: 286,298\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7L0zZdYRw3C_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0201.\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.1591 - accuracy: 0.9503 - val_loss: 0.0749 - val_accuracy: 0.9787\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.014430626211475785.\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0606 - accuracy: 0.9819 - val_loss: 0.0313 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.01036834238065184.\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 0.0286 - val_accuracy: 0.9904\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.007457588823428847.\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0348 - accuracy: 0.9893 - val_loss: 0.0201 - val_accuracy: 0.9934\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.005371942762314537.\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.0210 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0038775120567512366.\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0176 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.002806705664732254.\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0178 - val_accuracy: 0.9939\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.002039439357288101.\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0164 - val_accuracy: 0.9939\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0014896690244560313.\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0147 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001095741367357279.\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0148 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.000813479866945048.\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0145 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0006112306641301482.\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0151 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.00046631277777468366.\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00036247457473881936.\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0144 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.00028807125102990415.\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.0139 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0002347589399817094.\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0144 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00019655899987662886.\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.0143 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0001691875467292952.\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0141 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0001495750435333272.\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.0141 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0001355220709146876.\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0141 - val_accuracy: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1caa1691bc8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_decay = lambda epoch: 0.0001 + 0.02 * math.pow(1.0 / math.e, epoch / 3.0)\n",
    "decay_callback = LearningRateScheduler(lr_decay, verbose=1)\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=20,\n",
    "    validation_data=ds_val,\n",
    "    callbacks=[decay_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SwCAPICrxmRc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, SAVED_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XVL5ULexulp"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('mnist.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "51PTkdoPDOTW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip downloading\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('mnist.tflite')\n",
    "except:\n",
    "    print(\"Skip downloading\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
